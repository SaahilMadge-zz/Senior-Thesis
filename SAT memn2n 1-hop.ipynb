{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numQuestions  4\n",
      "[[u'In lines 2-8, the author of Passage 1 mentions activities that suggest dolphins', u'are unusually sensitive to their environment', u'do not generally thrive in captivity', u'have a unique type of intelligence', u'are uncommonly playful animals', u'have skills usually associated with humans'], [u'The author of Passage 2 would most likely respond to the last sentence of Passage 1 by', u'suggesting that intelligence in animals is virtually impossible to measure', u'observing that intelligence does not mean the same thing for every species', u'questioning the objectivity of the studies already conducted', u'noting that dolphin activities do not require a high level of intelligence', u'arguing that little is actually known about dolphin social behavior'], [u'The two passages differ in their views of dolphin intelligence in that Passage 1 states that dolphins', u'share a sophisticated culture; while Passage 2 contends that dolphin intelligence is roughly equal to human intelligence', u'are as intelligent as humans, while Passage 2 notes that dolphins outperform other animals', u'are more intelligent than most other animals, while Passage 2 points out that dolphins are less intelligent than other mammals', u'are highly intelligent, while Passage 2 suggests that there is not enough evidence to understand dolphin intelligence fully', u'have large brains, while Passage 2 argues that brain size does not signify intelligence'], [u'Which generalization about dolphins is supported by both passages?', u'They display self-awareness.', u'They are more emotional than other animals.', u'They learn at a rapid rate.', u'They have a certain degree of intelligence.', u'They have shown the ability to use tools.']]\n"
     ]
    }
   ],
   "source": [
    "# This is an implementation of the End-to-End Memory Network as defined by Sukhbaatar, et al. \n",
    "# We use k=1, i.e. have only one computational step in the network\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from triple_reader import triple_reader\n",
    "from question_reader import question_reader\n",
    "from gensim.models import word2vec\n",
    "from nltk.corpus import stopwords\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize word2vec model\n",
    "word_model = word2vec.Word2Vec.load_word2vec_format('word2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in file as tensors\n",
    "text_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/\"\n",
    "    \"Senior Thesis Code/ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/1/Triples/1-long2.txt\")\n",
    "    \n",
    "tr = triple_reader(text_file)\n",
    "# print tr.tripleList\n",
    "tensor = tr.tensor\n",
    "\n",
    "enMap = tr.enMap\n",
    "relMap = tr.relMap\n",
    "\n",
    "R = len(tensor)\n",
    "N = len(tensor[0])\n",
    "# dimension for encoding is arbitrary, we pick 20 here\n",
    "d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 6050)\n",
      "(110, 6050)\n"
     ]
    }
   ],
   "source": [
    "tensor_stack = np.hstack(tuple(tensor))\n",
    "print(tensor_stack.shape)\n",
    "print(N, N*R)\n",
    "\n",
    "X = T.lmatrix('X')\n",
    "q = T.dmatrix('q')\n",
    "y = T.lmatrix('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('saw', 0.52656813492727217, False, 'went'), ('distaste', 0.26808481582806276, True, 'critic')]\n"
     ]
    }
   ],
   "source": [
    "# Find the word in entity that's most similar to given word\n",
    "# default topsim to lowest possible python int\n",
    "def findSimEn(word):\n",
    "    topsim = None\n",
    "    topEn = None\n",
    "    for en in enMap:\n",
    "        if type(en) == int:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word_model.similarity(en, word)\n",
    "        except KeyError as e:\n",
    "            sim = None\n",
    "        if sim > topsim:\n",
    "            topsim = sim\n",
    "            topEn = en\n",
    "    return [topEn, topsim]\n",
    "\n",
    "def findSimRel(word):\n",
    "    topsim = None\n",
    "    topRel = None\n",
    "    for rel in relMap:\n",
    "        if type(rel) == int:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word_model.similarity(rel, word)\n",
    "        except KeyError as e:\n",
    "            sim = None\n",
    "        if sim > topsim:\n",
    "            topsim = sim\n",
    "            topRel = rel\n",
    "    return [topRel, topsim]\n",
    "\n",
    "# print findSimEn('critic')\n",
    "# print findSimRel('go')\n",
    "\n",
    "# Return top similarity, sim score, and isEn boolean\n",
    "def findTopEnOrRel(word):\n",
    "#     try:\n",
    "    [topEn, topEnsim] = findSimEn(word)\n",
    "    [topRel, topRelsim] = findSimRel(word)\n",
    "    if topEnsim > topRelsim:\n",
    "        return (topEn, topEnsim, True, word)\n",
    "    else:\n",
    "        return (topRel, topRelsim, False, word)\n",
    "        \n",
    "    # if can't find similarity, ignore it\n",
    "#     except KeyError as e:\n",
    "#         return [None, 0, False, word]\n",
    "    \n",
    "# Return top 2 sims for an array of words\n",
    "def findTopEnOrRelArr(wordArr):\n",
    "    topArrs = []\n",
    "    for word in wordArr:\n",
    "        top = findTopEnOrRel(word)\n",
    "#         print top\n",
    "        topArrs.append(top)\n",
    "#     print topArrs\n",
    "#     print topArrs\n",
    "    sortedTop = sorted(topArrs, key=lambda x: -x[1] if x[1] is not None else sys.maxint)\n",
    "#     print sortedTop\n",
    "    top1 = sortedTop[0]\n",
    "    top2 = None\n",
    "    # if the top is a relation, we have to pick an entity\n",
    "    if top1[2] == False:\n",
    "        curIndex = 1\n",
    "        while curIndex < len(sortedTop):\n",
    "            cur = sortedTop[curIndex]\n",
    "            if cur[2] == False:\n",
    "                curIndex += 1\n",
    "                continue\n",
    "            else:\n",
    "                top2 = cur\n",
    "                break\n",
    "    else:\n",
    "        top2 = sortedTop[1]\n",
    "    if top2 == None:\n",
    "        top2 = [0, 0, True]\n",
    "    return [top1, top2]\n",
    "\n",
    "print(findTopEnOrRelArr([\"critic\", \"went\", \"hi\", \"boat\", \"paint\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numQuestions  13\n",
      "[('Jerry', 1.0, True, u'Jerry'), ('narrator', 1.0, True, u'narrator')]\n",
      "[('Jerry', 1.0, True, u'Jerry'), ('narrator', 1.0, True, u'narrator')]\n",
      "[('This', 0.7025192721804896, True, u'The'), ('means', 0.62676256128193342, False, u'implies')]\n",
      "[('means', 1.0, False, u'means'), ('This', 0.42479429618445708, True, u'In')]\n",
      "[('seems', 0.50263214831747294, True, u'suggests'), ('This', 0.42479429618445708, True, u'In')]\n",
      "[('Jerry', 1.0, True, u'Jerry'), ('life', 0.99999999999999989, True, u'life')]\n",
      "[('narrator', 1.0, True, u'narrator'), ('This', 0.7025192721804896, True, u'The')]\n",
      "[('changed', 0.45613785554949016, False, u'changes'), ('This', 0.42479429618445708, True, u'In')]\n",
      "[('This', 0.7025192721804896, True, u'The'), ('seems', 0.50263214831747294, True, u'suggests')]\n",
      "[('means', 0.43558764504275427, False, u'indicates'), ('This', 0.42479429618445708, True, u'In')]\n",
      "[('means', 1.0, False, u'means'), ('This', 0.42479429618445708, True, u'In')]\n",
      "[('What', 0.74367242975250147, True, u'Which'), ('describes', 0.73243172798950995, False, u'characterizes')]\n",
      "[('class', 0.99999999999999978, True, u'class'), ('behavior', 0.54887286604937258, True, u'attitudes')]\n",
      "(165, 8)\n",
      "(165, 5)\n"
     ]
    }
   ],
   "source": [
    "q_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/Senior Thesis Code/\"\n",
    "\"ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/1/1-long2-q.txt\")\n",
    "\n",
    "qr = question_reader(q_file)\n",
    "\n",
    "# print qr.numQuestions\n",
    "\n",
    "numTrainQ = int(qr.numQuestions*(float(2)/3))\n",
    "numTestQ = qr.numQuestions - numTrainQ\n",
    "# print numTrainQ\n",
    "# print numTestQ\n",
    "\n",
    "CHOICES_PER_Q = 5\n",
    "\n",
    "train_Q = []\n",
    "test_Q = []\n",
    "# VECTORIZE BY FINDING TOP TWO SIMILAR TO EACH QUESTION, AND MAKING A 2-HOT VECTOR OF LENGTH N+R\n",
    "questions = qr.questionCombos\n",
    "for i in xrange(qr.numQuestions):\n",
    "    question = questions[i]\n",
    "    question_words = question[0].split(\" \")\n",
    "    # remove stopwords\n",
    "    question_words = [word for word in question_words if word not in stopwords.words('english')]\n",
    "    [top1, top2] = findTopEnOrRelArr(question_words)\n",
    "    print([top1, top2])\n",
    "    \n",
    "    # if word in question doesn't match, move on\n",
    "    if top1[0] == None:\n",
    "        continue\n",
    "    \n",
    "    # Now vectorize it to be of length N+R\n",
    "    if top1[2] == True:\n",
    "        index1 = enMap[top1[0]]\n",
    "    else:\n",
    "        index1 = N + relMap[top1[0]]\n",
    "    if top2[2] == True:\n",
    "        index2 = enMap[top2[0]]\n",
    "    else:\n",
    "        index2 = N + relMap[top2[0]]\n",
    "    curQVec = np.zeros(N+R)\n",
    "    curQVec[index1] = 1\n",
    "    curQVec[index2] = 1\n",
    "    if i < numTrainQ:\n",
    "        train_Q.append(curQVec)\n",
    "    else:\n",
    "        test_Q.append(curQVec)\n",
    "train_Q = np.array(train_Q)\n",
    "train_Q = train_Q.T\n",
    "test_Q = np.array(test_Q)\n",
    "test_Q = test_Q.T\n",
    "print(train_Q.shape)\n",
    "print(test_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a weight matrix of given size. \n",
    "# The matrix is initialized randomly with Gaussian distribution \n",
    "# with mean=0 and \\sigma=0.1\n",
    "def initializeWeightMatrix(in_size, out_size):\n",
    "    return theano.shared(0.1 * np.random.randn(in_size, out_size))\n",
    "\n",
    "# Create a bias vector of all zeros of given size\n",
    "def initializeBiasVector(size):\n",
    "    return theano.shared(np.zeros(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20]\n"
     ]
    }
   ],
   "source": [
    "# Initialize all our parameters, given our dimensions.\n",
    "# Input matrix has shape Nx(N*R)\n",
    "# Query matrix has shape 5xnumQ\n",
    "# A is the first matrix used to embed our input. It has size dxN\n",
    "# B is the matrix used to embed the query. It has size dx(N+R)\n",
    "# C is the next matrix used to embed our input. It has size dxN\n",
    "# W is the final matrix. Takes output O and produces result w_embedded. It has size 5xd\n",
    "\n",
    "def initializeParams(d, N):\n",
    "    A = initializeWeightMatrix(d,N)\n",
    "    B = initializeWeightMatrix(d,N+R)\n",
    "    C = initializeWeightMatrix(d,N)\n",
    "    W = initializeWeightMatrix(CHOICES_PER_Q,d)\n",
    "    \n",
    "#     A = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     B = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     C = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     W = theano.shared(initializeWeightMatrix(V, d))\n",
    "    return A, B, C, W\n",
    "\n",
    "A, B, C, W = initializeParams(d, N)\n",
    "weightMatrices = [A, B, C, W]\n",
    "print(W.shape.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the computational step\n",
    "# Given input matrix X, query q, and weight matrices, we perform a computational step,\n",
    "# also known as a \"hop\". Let M be the number of sentences\n",
    "def hopComputation(X, q, A, B, C, W):\n",
    "    #m_i = Ax_i\n",
    "    mem_matrix = A.dot(X) #dimension (dxN) x (Nx(NxR)) = dx(N*R)\n",
    "    #u = Bq\n",
    "    u = B.dot(q) #dimension (dx(N+R)) x ((N+R)xnumQ) = dxnumQ\n",
    "    #p_i = softmax(u^T m_i)\n",
    "    probs = T.nnet.softmax(u.T.dot(mem_matrix)) #dimension(numQxd)x(dx(N*R)) = numQx(N*R)\n",
    "    #C_i = Cx_i\n",
    "    c = C.dot(X) #dimension (dxN) x (Nx(NxR)) = dx(N*R)\n",
    "    o = c.dot(probs.T) #dimension (dx(N*R))x((N*R)xnumQ) = dxnumQ\n",
    "    \n",
    "    #w_embedded = Wo\n",
    "    w_embedded = W.dot(o).T #dimension (5xd)x(dxnumQ) = 5xnumQ.T = numQx5\n",
    "    \n",
    "    result = T.nnet.softmax(w_embedded)\n",
    "    return result\n",
    "    \n",
    "    #output = sum of c_matrix * probs\n",
    "#     o = (probs * c_embedded).sum(axis = 0)\n",
    "    #result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_hat = hopComputation(X, q, A, B, C, W)\n",
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "def inspect_inputs(i, node, fn):\n",
    "    print(i, node, \"input(s) value(s):\", fn.inputs, end='')\n",
    "\n",
    "def inspect_outputs(i, node, fn):\n",
    "    print(\" output(s) value(s):\", fn.outputs)\n",
    "    \n",
    "def detect_nan(i, node, fn):\n",
    "    for output in fn.outputs:\n",
    "        if (not isinstance(output[0], np.random.RandomState) and\n",
    "            np.isnan(output[0]).any()):\n",
    "            print('*** NaN detected ***')\n",
    "            theano.printing.debugprint(node)\n",
    "            print('Inputs : %s' % [input[0] for input in fn.inputs])\n",
    "            print('Outputs: %s' % [output[0] for output in fn.outputs])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Learning rate (chosen to be 0.01)\n",
    "epsilon = 0.1\n",
    "\n",
    "# This function trains our neural net, using stochastic gradient descent.\n",
    "def train_MemNN(loss, X, q, y, y_hat):\n",
    "    update_weights = []\n",
    "    for weightMatrix in weightMatrices:\n",
    "        update = T.grad(loss, weightMatrix)\n",
    "        update_weights.append((weightMatrix, weightMatrix - update * epsilon))\n",
    "    train_MemNN_func = theano.function(inputs=[X,q,y], outputs=[loss,y_hat], updates=update_weights, \n",
    "                        mode=theano.compile.MonitorMode(\n",
    "#                             pre_func=inspect_inputs,\n",
    "                            post_func=detect_nan))\n",
    "    return train_MemNN_func\n",
    "\n",
    "train_MemNN_func = train_MemNN(loss, X, q, y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(in_vect, question, answers, epochs=100):\n",
    "    train_errors = []\n",
    "    y_hats = []\n",
    "    for i in xrange(epochs):\n",
    "        error = 0\n",
    "        [cur_loss, cur_yhat] = train_MemNN_func(in_vect, question, answers)\n",
    "        error += cur_loss\n",
    "#         print(error)\n",
    "        train_errors.append(error)\n",
    "        y_hats.append(cur_yhat)\n",
    "    return [train_errors, y_hats]\n",
    "\n",
    "def test_model(in_vect, question):\n",
    "    # use a stub answers matrix, it doesn't really matter\n",
    "    print(question.shape)\n",
    "    [loss, y_hat] = train_MemNN_func(in_vect, question, np.zeros((len(question[0]), 5)).astype(int))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6085349726977189, 1.6085338863987018, 1.6085327992566743, 1.6085317112704904, 1.6085306224390035, 1.6085295327610643, 1.6085284422355235, 1.6085273508612292, 1.6085262586370297, 1.6085251655617707, 1.6085240716342981, 1.6085229768534541, 1.6085218812180817, 1.6085207847270226, 1.6085196873791163, 1.6085185891732008, 1.6085174901081134, 1.60851639018269, 1.6085152893957655, 1.6085141877461726, 1.6085130852327434, 1.6085119818543088, 1.6085108776096975, 1.6085097724977375, 1.6085086665172557, 1.6085075596670775, 1.6085064519460264, 1.6085053433529251, 1.6085042338865951, 1.608503123545856, 1.6085020123295268, 1.6085009002364246, 1.6084997872653646, 1.6084986734151625, 1.6084975586846306, 1.6084964430725814, 1.6084953265778248, 1.6084942091991705, 1.6084930909354254, 1.6084919717853972, 1.6084908517478889, 1.6084897308217063, 1.6084886090056503, 1.6084874862985226, 1.6084863626991224, 1.6084852382062473, 1.6084841128186946, 1.6084829865352603, 1.6084818593547368, 1.6084807312759182, 1.6084796022975945, 1.6084784724185566, 1.6084773416375924, 1.6084762099534886, 1.6084750773650311, 1.6084739438710038, 1.6084728094701906, 1.6084716741613714, 1.6084705379433266, 1.6084694008148352, 1.6084682627746736, 1.6084671238216182, 1.6084659839544428, 1.6084648431719208, 1.6084637014728229, 1.6084625588559189, 1.6084614153199783, 1.6084602708637674, 1.6084591254860523, 1.6084579791855971, 1.6084568319611641, 1.6084556838115154, 1.6084545347354098, 1.6084533847316069, 1.6084522337988629, 1.6084510819359337, 1.6084499291415728, 1.6084487754145331, 1.6084476207535656, 1.60844646515742, 1.6084453086248442, 1.6084441511545848, 1.6084429927453878, 1.6084418333959958, 1.6084406731051515, 1.6084395118715955, 1.6084383496940673, 1.6084371865713043, 1.6084360225020429, 1.608434857485018, 1.6084336915189625, 1.6084325246026079, 1.6084313567346853, 1.6084301879139229, 1.608429018139047, 1.6084278474087852, 1.6084266757218599, 1.6084255030769947, 1.6084243294729104, 1.6084231549083263, 1.608421979381961, 1.6084208028925302, 1.6084196254387499, 1.608418447019333, 1.6084172676329909, 1.6084160872784345, 1.6084149059543726, 1.6084137236595129, 1.6084125403925598, 1.6084113561522182, 1.6084101709371907, 1.6084089847461782, 1.6084077975778803, 1.6084066094309946, 1.6084054203042171, 1.6084042301962429, 1.6084030391057653, 1.6084018470314756, 1.6084006539720637, 1.6083994599262181, 1.6083982648926254, 1.6083970688699711, 1.6083958718569387, 1.6083946738522097, 1.608393474854465, 1.6083922748623833, 1.6083910738746419, 1.6083898718899161, 1.6083886689068796, 1.6083874649242054, 1.6083862599405634, 1.6083850539546236, 1.6083838469650529, 1.6083826389705171, 1.6083814299696799, 1.6083802199612049, 1.6083790089437522, 1.6083777969159816, 1.6083765838765505, 1.6083753698241148, 1.6083741547573287, 1.6083729386748449, 1.6083717215753144, 1.6083705034573865, 1.6083692843197093, 1.6083680641609281, 1.6083668429796878, 1.6083656207746304, 1.6083643975443978, 1.6083631732876282, 1.6083619480029601, 1.6083607216890288, 1.608359494344469, 1.6083582659679125, 1.6083570365579909, 1.608355806113333, 1.608354574632566, 1.6083533421143159, 1.6083521085572066, 1.6083508739598609, 1.6083496383208984, 1.6083484016389384, 1.6083471639125981, 1.608345925140493, 1.608344685321236, 1.6083434444534399, 1.6083422025357146, 1.6083409595666682, 1.6083397155449084, 1.6083384704690389, 1.6083372243376632, 1.6083359771493833, 1.6083347289027987, 1.6083334795965065, 1.6083322292291042, 1.6083309777991854, 1.6083297253053428, 1.608328471746167, 1.6083272171202476, 1.6083259614261716, 1.6083247046625244, 1.6083234468278897, 1.6083221879208498, 1.6083209279399842, 1.6083196668838717, 1.6083184047510883, 1.6083171415402093, 1.6083158772498067, 1.6083146118784528, 1.6083133454247163, 1.6083120778871645, 1.608310809264363, 1.6083095395548757, 1.6083082687572645, 1.6083069968700894, 1.6083057238919092, 1.6083044498212793, 1.6083031746567553, 1.60830189839689, 1.6083006210402331, 1.6082993425853349, 1.608298063030742, 1.6082967823749998, 1.6082955006166517, 1.6082942177542392, 1.6082929337863021, 1.6082916487113783, 1.6082903625280032, 1.6082890752347114, 1.6082877868300351, 1.6082864973125044, 1.6082852066806475, 1.6082839149329908, 1.6082826220680595, 1.6082813280843755, 1.6082800329804599, 1.6082787367548312, 1.6082774394060064, 1.6082761409325013, 1.6082748413328276, 1.6082735406054973, 1.6082722387490196, 1.6082709357619016, 1.6082696316426479, 1.6082683263897628, 1.6082670200017473, 1.6082657124771012, 1.6082644038143215, 1.6082630940119036, 1.6082617830683417, 1.6082604709821273, 1.6082591577517498, 1.6082578433756964, 1.6082565278524537, 1.6082552111805046, 1.608253893358331, 1.6082525743844129, 1.6082512542572278, 1.6082499329752511, 1.6082486105369571, 1.6082472869408173, 1.6082459621853009, 1.608244636268876, 1.6082433091900079, 1.6082419809471609, 1.6082406515387955, 1.6082393209633725, 1.6082379892193484, 1.6082366563051786, 1.6082353222193175, 1.608233986960216, 1.6082326505263234, 1.6082313129160863, 1.6082299741279509, 1.6082286341603598, 1.6082272930117545, 1.6082259506805736, 1.6082246071652539, 1.6082232624642305, 1.6082219165759362, 1.6082205694988019, 1.6082192212312549, 1.6082178717717235, 1.6082165211186306, 1.6082151692703994, 1.6082138162254493, 1.6082124619821987, 1.6082111065390639, 1.6082097498944576, 1.6082083920467927, 1.608207032994478, 1.6082056727359209, 1.6082043112695263, 1.6082029485936986, 1.6082015847068372, 1.6082002196073417, 1.6081988532936093, 1.6081974857640335, 1.608196117017006, 1.6081947470509192, 1.6081933758641591, 1.6081920034551123, 1.608190629822162, 1.6081892549636898, 1.6081878788780748, 1.608186501563694, 1.6081851230189228, 1.6081837432421331, 1.6081823622316955, 1.6081809799859781, 1.6081795965033474, 1.6081782117821664, 1.6081768258207967, 1.6081754386175979, 1.608174050170927, 1.6081726604791389, 1.6081712695405859, 1.6081698773536182, 1.6081684839165837, 1.608167089227829, 1.6081656932856967, 1.6081642960885283, 1.6081628976346631, 1.6081614979224375, 1.6081600969501861, 1.6081586947162405, 1.6081572912189315, 1.6081558864565855, 1.6081544804275283, 1.6081530731300828, 1.6081516645625697, 1.6081502547233069, 1.6081488436106106, 1.6081474312227946, 1.6081460175581699, 1.6081446026150457, 1.6081431863917284, 1.6081417688865225, 1.6081403500977298, 1.6081389300236502, 1.6081375086625802, 1.6081360860128153, 1.6081346620726482, 1.6081332368403682, 1.6081318103142634, 1.6081303824926194, 1.6081289533737189, 1.6081275229558423, 1.6081260912372684, 1.608124658216272, 1.6081232238911274, 1.6081217882601055, 1.6081203513214739, 1.6081189130735001, 1.6081174735144459, 1.6081160326425743, 1.6081145904561434, 1.6081131469534091, 1.6081117021326263, 1.6081102559920462, 1.6081088085299169, 1.6081073597444857, 1.6081059096339965, 1.6081044581966912, 1.608103005430809, 1.6081015513345855, 1.6081000959062559, 1.6080986391440515, 1.6080971810462015, 1.6080957216109324, 1.6080942608364686, 1.6080927987210309, 1.6080913352628399, 1.6080898704601105, 1.6080884043110582, 1.6080869368138937, 1.6080854679668259, 1.6080839977680617, 1.6080825262158049, 1.6080810533082566, 1.6080795790436153, 1.6080781034200777, 1.6080766264358373, 1.6080751480890845, 1.6080736683780086, 1.6080721873007953, 1.6080707048556278, 1.6080692210406859, 1.6080677358541489, 1.6080662492941917, 1.6080647613589873, 1.6080632720467054, 1.6080617813555147, 1.6080602892835789, 1.6080587958290611, 1.6080573009901205, 1.6080558047649145, 1.6080543071515971, 1.6080528081483203, 1.6080513077532328, 1.6080498059644817, 1.6080483027802099, 1.6080467981985587, 1.608045292217666, 1.6080437848356688, 1.6080422760506983, 1.6080407658608855, 1.6080392542643582, 1.6080377412592406, 1.6080362268436552, 1.6080347110157214, 1.6080331937735548, 1.6080316751152708, 1.6080301550389793, 1.6080286335427894, 1.6080271106248065, 1.608025586283133, 1.6080240605158698, 1.6080225333211133, 1.6080210046969585, 1.6080194746414973, 1.6080179431528185, 1.608016410229008, 1.6080148758681494, 1.608013340068323, 1.6080118028276069, 1.6080102641440757, 1.6080087240158014, 1.6080071824408539, 1.6080056394172983, 1.6080040949431993, 1.6080025490166168, 1.6080010016356094, 1.6079994527982313, 1.6079979025025353, 1.60799635074657, 1.6079947975283819, 1.6079932428460144, 1.6079916866975086, 1.6079901290809013, 1.607988569994228, 1.6079870094355204, 1.6079854474028068, 1.6079838838941134, 1.6079823189074638, 1.6079807524408773, 1.6079791844923716, 1.607977615059961, 1.6079760441416564, 1.6079744717354663, 1.6079728978393959, 1.6079713224514474, 1.60796974556962, 1.6079681671919108, 1.6079665873163129, 1.6079650059408159, 1.6079634230634081, 1.6079618386820738, 1.6079602527947934, 1.6079586653995461, 1.6079570764943067, 1.6079554860770475, 1.6079538941457381, 1.6079523006983438, 1.6079507057328282, 1.607949109247151, 1.6079475112392689, 1.6079459117071366, 1.6079443106487041, 1.6079427080619191, 1.607941103944726, 1.6079394982950665, 1.6079378911108793, 1.6079362823900984, 1.6079346721306571, 1.6079330603304833, 1.6079314469875037, 1.6079298320996405, 1.6079282156648123, 1.6079265976809369, 1.6079249781459266, 1.6079233570576916, 1.607921734414139, 1.6079201102131715, 1.6079184844526897, 1.6079168571305915, 1.6079152282447702, 1.6079135977931169, 1.6079119657735188, 1.6079103321838604, 1.6079086970220229, 1.6079070602858834, 1.6079054219733171, 1.6079037820821953, 1.6079021406103857, 1.6079004975557529, 1.6078988529161589, 1.6078972066894617, 1.6078955588735155, 1.6078939094661726, 1.6078922584652813, 1.6078906058686859, 1.6078889516742287, 1.6078872958797474, 1.6078856384830771, 1.6078839794820494, 1.6078823188744922, 1.6078806566582311, 1.607878992831087, 1.6078773273908782, 1.6078756603354192, 1.6078739916625215, 1.6078723213699928, 1.6078706494556381, 1.6078689759172577, 1.6078673007526503, 1.6078656239596092, 1.6078639455359258, 1.607862265479387, 1.6078605837877769, 1.6078589004588759, 1.6078572154904611, 1.6078555288803058, 1.6078538406261802, 1.6078521507258503, 1.6078504591770801, 1.6078487659776277, 1.6078470711252499, 1.6078453746176993, 1.6078436764527246, 1.6078419766280709, 1.6078402751414806, 1.6078385719906911, 1.6078368671734382, 1.6078351606874521, 1.6078334525304605, 1.6078317427001878, 1.6078300311943541, 1.6078283180106763, 1.6078266031468671, 1.6078248866006364, 1.60782316836969, 1.6078214484517304, 1.6078197268444558, 1.6078180035455609, 1.6078162785527381, 1.6078145518636742, 1.6078128234760527, 1.6078110933875547, 1.6078093615958566, 1.6078076280986306, 1.6078058928935466, 1.6078041559782701, 1.6078024173504621, 1.6078006770077808, 1.607798934947881, 1.6077971911684124, 1.6077954456670216, 1.6077936984413519, 1.6077919494890429, 1.6077901988077288, 1.6077884463950418, 1.6077866922486097, 1.6077849363660563, 1.6077831787450019, 1.6077814193830622, 1.6077796582778496, 1.6077778954269739, 1.6077761308280385, 1.6077743644786446, 1.6077725963763898, 1.6077708265188664, 1.6077690549036634, 1.6077672815283666, 1.6077655063905572, 1.6077637294878131, 1.6077619508177072, 1.6077601703778093, 1.6077583881656849, 1.607756604178896, 1.6077548184150001, 1.6077530308715509, 1.6077512415460977, 1.6077494504361873, 1.6077476575393603, 1.6077458628531556, 1.6077440663751059, 1.6077422681027411, 1.6077404680335874, 1.6077386661651654, 1.6077368624949937, 1.6077350570205848, 1.6077332497394488, 1.6077314406490903, 1.6077296297470109, 1.6077278170307081, 1.6077260024976738, 1.6077241861453979, 1.6077223679713644, 1.6077205479730545, 1.6077187261479435, 1.6077169024935052, 1.6077150770072055, 1.6077132496865105, 1.6077114205288787, 1.6077095895317657, 1.6077077566926228, 1.6077059220088972, 1.6077040854780316, 1.6077022470974642, 1.6077004068646303, 1.607698564776959, 1.6076967208318755, 1.6076948750268034, 1.6076930273591583, 1.6076911778263532, 1.6076893264257968, 1.6076874731548934, 1.6076856180110428, 1.6076837609916415, 1.6076819020940789, 1.6076800413157435, 1.6076781786540171, 1.6076763141062775, 1.6076744476698992, 1.6076725793422504, 1.6076707091206968, 1.6076688370025987, 1.607666962985312, 1.6076650870661875, 1.6076632092425738, 1.6076613295118123, 1.607659447871242, 1.6076575643181958, 1.6076556788500032, 1.6076537914639892, 1.6076519021574731, 1.6076500109277709, 1.6076481177721937, 1.6076462226880479, 1.6076443256726352, 1.6076424267232536, 1.6076405258371951, 1.6076386230117481, 1.6076367182441962, 1.6076348115318182, 1.6076329028718885, 1.6076309922616767, 1.6076290796984471, 1.6076271651794616, 1.6076252487019744, 1.607623330263237, 1.6076214098604957, 1.6076194874909917, 1.6076175631519622, 1.6076156368406389, 1.6076137085542497, 1.6076117782900163, 1.6076098460451573, 1.6076079118168853, 1.6076059756024088, 1.6076040373989311, 1.6076020972036509, 1.607600155013762, 1.607598210826453, 1.6075962646389081, 1.6075943164483071, 1.6075923662518239, 1.6075904140466277, 1.607588459829884, 1.6075865035987513, 1.6075845453503856, 1.6075825850819359, 1.6075806227905471, 1.6075786584733596, 1.6075766921275074, 1.6075747237501219, 1.6075727533383264, 1.6075707808892421, 1.6075688063999838, 1.6075668298676613, 1.607564851289379, 1.6075628706622374, 1.6075608879833312, 1.607558903249749, 1.607556916458577, 1.6075549276068934, 1.6075529366917731, 1.6075509437102855, 1.6075489486594947, 1.6075469515364591, 1.6075449523382328, 1.6075429510618646, 1.6075409477043971, 1.6075389422628694, 1.6075369347343142, 1.6075349251157587, 1.6075329134042258, 1.6075308995967332, 1.6075288836902923, 1.6075268656819095, 1.6075248455685864, 1.6075228233473196, 1.6075207990150993, 1.6075187725689113, 1.6075167440057347, 1.6075147133225454, 1.607512680516312, 1.6075106455839985, 1.6075086085225634, 1.6075065693289605, 1.6075045280001365, 1.6075024845330339, 1.6075004389245897, 1.6074983911717349, 1.6074963412713952, 1.6074942892204918, 1.6074922350159386, 1.6074901786546452, 1.6074881201335149, 1.6074860594494464, 1.6074839965993322, 1.6074819315800593, 1.6074798643885087, 1.6074777950215573, 1.6074757234760739, 1.6074736497489239, 1.6074715738369663, 1.6074694957370537, 1.607467415446034, 1.6074653329607493, 1.6074632482780353, 1.6074611613947225, 1.6074590723076361, 1.6074569810135941, 1.6074548875094101, 1.6074527917918917, 1.6074506938578401, 1.6074485937040515, 1.6074464913273152, 1.6074443867244159, 1.6074422798921313, 1.6074401708272341, 1.6074380595264908, 1.6074359459866614, 1.6074338302045017, 1.6074317121767592, 1.6074295919001771, 1.6074274693714927, 1.607425344587436, 1.6074232175447321, 1.6074210882401001, 1.6074189566702526, 1.6074168228318959, 1.6074146867217323, 1.6074125483364543, 1.6074104076727522, 1.6074082647273071, 1.6074061194967959, 1.607403971977889, 1.6074018221672506, 1.6073996700615376, 1.6073975156574027, 1.6073953589514904, 1.6073931999404414, 1.6073910386208876, 1.6073888749894558, 1.6073867090427671, 1.6073845407774356, 1.6073823701900691, 1.6073801972772694, 1.607378022035632, 1.6073758444617452, 1.6073736645521923, 1.6073714823035496, 1.6073692977123866, 1.6073671107752669, 1.6073649214887469, 1.6073627298493784, 1.6073605358537046, 1.6073583394982636, 1.607356140779586, 1.6073539396941969, 1.6073517362386147, 1.6073495304093501, 1.6073473222029084, 1.6073451116157886, 1.607342898644482, 1.607340683285474, 1.6073384655352427, 1.6073362453902609, 1.6073340228469923, 1.6073317979018971, 1.6073295705514266, 1.6073273407920261, 1.6073251086201337, 1.6073228740321808, 1.6073206370245934, 1.6073183975937884, 1.607316155736177, 1.6073139114481649, 1.6073116647261492, 1.6073094155665202, 1.6073071639656622, 1.6073049099199515, 1.6073026534257588, 1.6073003944794473, 1.6072981330773728, 1.6072958692158843, 1.6072936028913245, 1.6072913341000283, 1.6072890628383236, 1.607286789102532, 1.6072845128889675, 1.6072822341939366, 1.6072799530137392, 1.6072776693446684, 1.6072753831830096, 1.6072730945250411, 1.6072708033670342, 1.607268509705253, 1.6072662135359541, 1.6072639148553873, 1.607261613659795, 1.6072593099454116, 1.6072570037084655, 1.6072546949451763, 1.6072523836517583, 1.6072500698244159, 1.6072477534593486, 1.6072454345527465, 1.6072431131007932, 1.6072407890996652, 1.6072384625455309, 1.6072361334345513, 1.6072338017628802, 1.6072314675266639, 1.6072291307220405, 1.6072267913451408, 1.6072244493920893, 1.6072221048590016, 1.6072197577419849, 1.6072174080371406, 1.6072150557405616, 1.607212700848333, 1.6072103433565321, 1.6072079832612292, 1.6072056205584855, 1.607203255244356, 1.6072008873148869, 1.6071985167661171, 1.6071961435940776, 1.6071937677947905, 1.6071913893642715, 1.6071890082985278, 1.6071866245935587, 1.6071842382453556, 1.6071818492499015, 1.6071794576031722, 1.6071770633011351, 1.6071746663397493, 1.6071722667149659, 1.6071698644227284, 1.6071674594589718, 1.6071650518196237, 1.6071626415006024, 1.6071602284978184, 1.6071578128071746, 1.6071553944245653, 1.6071529733458767, 1.607150549566986, 1.6071481230837632, 1.6071456938920696, 1.6071432619877581, 1.6071408273666727, 1.6071383900246503, 1.607135949957518, 1.6071335071610957, 1.6071310616311945, 1.6071286133636158, 1.6071261623541553, 1.6071237085985972, 1.6071212520927183, 1.6071187928322874, 1.6071163308130645, 1.6071138660308, 1.6071113984812375, 1.6071089281601099, 1.6071064550631424, 1.6071039791860526, 1.6071015005245468, 1.6070990190743251, 1.6070965348310771, 1.607094047790484, 1.6070915579482195, 1.6070890652999461, 1.6070865698413188, 1.6070840715679846, 1.6070815704755788, 1.607079066559731, 1.6070765598160588, 1.6070740502401732, 1.6070715378276754, 1.6070690225741562, 1.6070665044751999, 1.6070639835263789, 1.6070614597232593, 1.6070589330613951, 1.6070564035363333, 1.6070538711436111, 1.6070513358787553, 1.6070487977372852, 1.6070462567147101, 1.60704371280653, 1.6070411660082347, 1.6070386163153059, 1.6070360637232153, 1.6070335082274252, 1.6070309498233888, 1.6070283885065484, 1.6070258242723396, 1.6070232571161853, 1.6070206870335006, 1.6070181140196913, 1.6070155380701523, 1.6070129591802698, 1.6070103773454196, 1.6070077925609687, 1.6070052048222738, 1.607002614124682, 1.6070000204635297, 1.6069974238341451, 1.6069948242318459, 1.606992221651939, 1.606989616089723, 1.6069870075404851, 1.6069843959995032, 1.6069817814620455, 1.6069791639233693, 1.6069765433787226, 1.6069739198233437, 1.6069712932524591, 1.6069686636612874, 1.6069660310450351, 1.6069633953988993, 1.606960756718067, 1.6069581149977148, 1.6069554702330093, 1.6069528224191059, 1.6069501715511501, 1.6069475176242773, 1.6069448606336127, 1.6069422005742704, 1.606939537441354, 1.6069368712299572, 1.6069342019351633, 1.6069315295520437, 1.6069288540756597, 1.6069261755010633, 1.6069234938232946, 1.6069208090373834, 1.6069181211383479, 1.6069154301211972, 1.6069127359809281, 1.6069100387125277, 1.6069073383109709, 1.606904634771223, 1.606901928088238, 1.6068992182569584, 1.6068965052723163, 1.6068937891292332, 1.606891069822618, 1.6068883473473703, 1.6068856216983767, 1.6068828928705152, 1.6068801608586498, 1.6068774256576352, 1.6068746872623143, 1.6068719456675185, 1.6068692008680678, 1.6068664528587711, 1.6068637016344263, 1.606860947189819, 1.6068581895197236, 1.6068554286189038, 1.6068526644821111, 1.6068498971040852, 1.6068471264795543, 1.6068443526032357, 1.606841575469834, 1.6068387950740426, 1.6068360114105433, 1.6068332244740058, 1.6068304342590882, 1.6068276407604365, 1.6068248439726858, 1.6068220438904575, 1.6068192405083619, 1.606816433820998, 1.6068136238229522, 1.6068108105087984, 1.6068079938730988, 1.6068051739104041, 1.6068023506152516, 1.6067995239821662, 1.6067966940056628, 1.6067938606802412, 1.6067910240003906, 1.6067881839605882, 1.6067853405552965, 1.6067824937789676, 1.6067796436260411, 1.6067767900909429, 1.6067739331680868, 1.6067710728518747, 1.6067682091366946, 1.6067653420169226, 1.6067624714869231, 1.6067595975410447, 1.6067567201736261]\n",
      "[[ 0.20074805  0.1998381   0.19914626  0.20089225  0.19937535]\n",
      " [ 0.20074805  0.1998381   0.19914626  0.20089225  0.19937535]\n",
      " [ 0.2008181   0.19982245  0.19906286  0.20097894  0.19931765]\n",
      " [ 0.2008181   0.19982245  0.19906286  0.20097894  0.19931765]\n",
      " [ 0.20076324  0.19983489  0.19912279  0.20092007  0.19935901]\n",
      " [ 0.2007893   0.19982816  0.19910193  0.20093629  0.19934432]\n",
      " [ 0.20076336  0.19983525  0.19912364  0.20091721  0.19936055]\n",
      " [ 0.20079241  0.1998278   0.19909284  0.2009498   0.19933715]]\n"
     ]
    }
   ],
   "source": [
    "in_vect = tensor_stack.astype(int)\n",
    "question = train_Q.astype(int)\n",
    "answers = np.array([np.array([0,1,0,0,0]),\n",
    "                    np.array([1,0,0,0,0]),\n",
    "                    np.array([0,0,0,1,0]),\n",
    "                    np.array([0,0,0,0,1]),\n",
    "                    np.array([1,0,0,0,0]),\n",
    "                    np.array([1,0,0,0,0]),\n",
    "                    np.array([0,0,0,1,0]),\n",
    "                    np.array([0,0,0,1,0])\n",
    "                   ]).astype(int)\n",
    "\n",
    "# print(in_vect)\n",
    "# print(question)\n",
    "# print(answers)\n",
    "# print(type(in_vect[0][0]))\n",
    "[train_errors, y_hats] = train_model(in_vect, question, answers, 1000)\n",
    "print(train_errors)\n",
    "print(y_hats[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 5)\n",
      "[ 0.20076408  0.19983459  0.19912184  0.20092103  0.19935846]\n",
      "[ 0.20081901  0.19982212  0.19906183  0.20097998  0.19931705]\n",
      "[ 0.20081901  0.19982212  0.19906183  0.20097998  0.19931705]\n",
      "[ 0.20062046  0.19986605  0.19928817  0.2007506   0.19947472]\n",
      "[ 0.2006447   0.19986138  0.19926182  0.20077518  0.19945692]\n"
     ]
    }
   ],
   "source": [
    "res = test_model(in_vect, test_Q.astype(int))\n",
    "for q in res:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
