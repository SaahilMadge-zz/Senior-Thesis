{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is an implementation of the End-to-End Memory Network as defined by Sukhbaatar, et al. \n",
    "# We use k=1, i.e. have only one computational step in the network\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from triple_reader import triple_reader\n",
    "from question_reader import question_reader\n",
    "from gensim.models import word2vec\n",
    "from nltk.corpus import stopwords\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize word2vec model\n",
    "word_model = word2vec.Word2Vec.load_word2vec_format('word2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in file as tensors\n",
    "text_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/\"\n",
    "    \"Senior Thesis Code/ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/1/Triples/1-long1.txt\")\n",
    "    \n",
    "tr = triple_reader(text_file)\n",
    "# print tr.tripleList\n",
    "tensor = tr.tensor\n",
    "\n",
    "enMap = tr.enMap\n",
    "relMap = tr.relMap\n",
    "\n",
    "R = len(tensor)\n",
    "N = len(tensor[0])\n",
    "# dimension for encoding is arbitrary, we pick 20 here\n",
    "d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 2759)\n",
      "(89, 2759)\n"
     ]
    }
   ],
   "source": [
    "tensor_stack = np.hstack(tuple(tensor))\n",
    "print(tensor_stack.shape)\n",
    "print(N, N*R)\n",
    "\n",
    "X = T.lmatrix('X')\n",
    "q = T.dmatrix('q')\n",
    "y = T.lmatrix('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author', 0.31762739449640298]\n",
      "['start', 0.41564052326381096]\n",
      "[('was', 0.47963733397180919, False, 'went'), ('author', 0.31762739449640298, True, 'critic')]\n"
     ]
    }
   ],
   "source": [
    "# Find the word in entity that's most similar to given word\n",
    "# default topsim to lowest possible python int\n",
    "def findSimEn(word):\n",
    "    topsim = None\n",
    "    topEn = None\n",
    "    for en in enMap:\n",
    "        if type(en) == int:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word_model.similarity(en, word)\n",
    "        except KeyError as e:\n",
    "            sim = None\n",
    "        if sim > topsim:\n",
    "            topsim = sim\n",
    "            topEn = en\n",
    "    return [topEn, topsim]\n",
    "\n",
    "def findSimRel(word):\n",
    "    topsim = None\n",
    "    topRel = None\n",
    "    for rel in relMap:\n",
    "        if type(rel) == int:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word_model.similarity(rel, word)\n",
    "        except KeyError as e:\n",
    "            sim = None\n",
    "        if sim > topsim:\n",
    "            topsim = sim\n",
    "            topRel = rel\n",
    "    return [topRel, topsim]\n",
    "\n",
    "print findSimEn('critic')\n",
    "print findSimRel('go')\n",
    "\n",
    "# Return top similarity, sim score, and isEn boolean\n",
    "def findTopEnOrRel(word):\n",
    "#     try:\n",
    "    [topEn, topEnsim] = findSimEn(word)\n",
    "    [topRel, topRelsim] = findSimRel(word)\n",
    "    if topEnsim > topRelsim:\n",
    "        return (topEn, topEnsim, True, word)\n",
    "    else:\n",
    "        return (topRel, topRelsim, False, word)\n",
    "        \n",
    "    # if can't find similarity, ignore it\n",
    "#     except KeyError as e:\n",
    "#         return [None, 0, False, word]\n",
    "    \n",
    "# Return top 2 sims for an array of words\n",
    "def findTopEnOrRelArr(wordArr):\n",
    "    topArrs = []\n",
    "    for word in wordArr:\n",
    "        top = findTopEnOrRel(word)\n",
    "#         print top\n",
    "        topArrs.append(top)\n",
    "#     print topArrs\n",
    "#     print topArrs\n",
    "    sortedTop = sorted(topArrs, key=lambda x: -x[1] if x[1] is not None else sys.maxint)\n",
    "#     print sortedTop\n",
    "    top1 = sortedTop[0]\n",
    "    top2 = None\n",
    "    # if the top is a relation, we have to pick an entity\n",
    "    if top1[2] == False:\n",
    "        curIndex = 1\n",
    "        while curIndex < len(sortedTop):\n",
    "            cur = sortedTop[curIndex]\n",
    "            if cur[2] == False:\n",
    "                curIndex += 1\n",
    "                continue\n",
    "            else:\n",
    "                top2 = cur\n",
    "                break\n",
    "    else:\n",
    "        top2 = sortedTop[1]\n",
    "    if top2 == None:\n",
    "        top2 = [0, 0, True]\n",
    "    return [top1, top2]\n",
    "\n",
    "print findTopEnOrRelArr([\"critic\", \"went\", \"hi\", \"boat\", \"paint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numQuestions  12\n",
      "[('It', 0.60106851750939438, True, u'The'), ('available', 0.35666711035229737, False, u'used')]\n",
      "[('requires', 0.53755015740882195, False, u'means'), ('more', 0.43554002125196029, True, u'nearly')]\n",
      "[('available', 0.35666711035229737, False, u'used'), ('It', 0.3241844469421169, True, u'In')]\n",
      "[('It', 0.60106851750939438, True, u'The'), ('examines', 0.44328536315913181, False, u'refers')]\n",
      "[('It', 0.60106851750939438, True, u'The'), ('misunderstood', 0.43356134230254451, True, u'referred')]\n",
      "[('cultures', 0.99999999999999978, True, u'cultures'), ('examines', 0.31791871184703069, False, u'describe')]\n",
      "[('start', 0.68539480759901428, False, u'begin'), ('It', 0.60106851750939438, True, u'The')]\n",
      "[('author', 0.99999999999999989, True, u'author'), ('historians', 0.99999999999999978, True, u'historians')]\n",
      "(120, 8)\n"
     ]
    }
   ],
   "source": [
    "q_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/Senior Thesis Code/\"\n",
    "\"ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/1/1-long1-q.txt\")\n",
    "\n",
    "qr = question_reader(q_file)\n",
    "\n",
    "# print qr.numQuestions\n",
    "\n",
    "numTrainQ = int(qr.numQuestions*(float(2)/3))\n",
    "numTestQ = qr.numQuestions - numTrainQ\n",
    "# print numTrainQ\n",
    "# print numTestQ\n",
    "\n",
    "CHOICES_PER_Q = 5\n",
    "\n",
    "train_Q = []\n",
    "# VECTORIZE BY FINDING TOP TWO SIMILAR TO EACH QUESTION, AND MAKING A 2-HOT VECTOR OF LENGTH N+R\n",
    "questions = qr.questionCombos\n",
    "for i in xrange(numTrainQ):\n",
    "    question = questions[i]\n",
    "    question_words = question[0].split(\" \")\n",
    "    # remove stopwords\n",
    "    question_words = [word for word in question_words if word not in stopwords.words('english')]\n",
    "    [top1, top2] = findTopEnOrRelArr(question_words)\n",
    "    print([top1, top2])\n",
    "    \n",
    "    # if word in question doesn't match, move on\n",
    "    if top1[0] == None:\n",
    "        continue\n",
    "    \n",
    "    # Now vectorize it to be of length N+R\n",
    "    if top1[2] == True:\n",
    "        index1 = enMap[top1[0]]\n",
    "    else:\n",
    "        index1 = N + relMap[top1[0]]\n",
    "    if top2[2] == True:\n",
    "        index2 = enMap[top2[0]]\n",
    "    else:\n",
    "        index2 = N + relMap[top2[0]]\n",
    "    curQVec = np.zeros(N+R)\n",
    "    curQVec[index1] = 1\n",
    "    curQVec[index2] = 1\n",
    "    train_Q.append(curQVec)\n",
    "train_Q = np.array(train_Q)\n",
    "train_Q = train_Q.T\n",
    "print(train_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a weight matrix of given size. \n",
    "# The matrix is initialized randomly with Gaussian distribution \n",
    "# with mean=0 and \\sigma=0.1\n",
    "def initializeWeightMatrix(in_size, out_size):\n",
    "    return theano.shared(0.1 * np.random.randn(in_size, out_size))\n",
    "\n",
    "# Create a bias vector of all zeros of given size\n",
    "def initializeBiasVector(size):\n",
    "    return theano.shared(np.zeros(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20]\n"
     ]
    }
   ],
   "source": [
    "# Initialize all our parameters, given our dimensions.\n",
    "# Input matrix has shape Nx(N*R)\n",
    "# Query matrix has shape 5xnumQ\n",
    "# A is the first matrix used to embed our input. It has size dxN\n",
    "# B is the matrix used to embed the query. It has size dx(N+R)\n",
    "# C is the next matrix used to embed our input. It has size dxN\n",
    "# W is the final matrix. Takes output O and produces result w_embedded. It has size 5xd\n",
    "\n",
    "def initializeParams(d, N):\n",
    "    A = initializeWeightMatrix(d,N)\n",
    "    B = initializeWeightMatrix(d,N+R)\n",
    "    C = initializeWeightMatrix(d,N)\n",
    "    W = initializeWeightMatrix(CHOICES_PER_Q,d)\n",
    "    \n",
    "#     A = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     B = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     C = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     W = theano.shared(initializeWeightMatrix(V, d))\n",
    "    return A, B, C, W\n",
    "\n",
    "A, B, C, W = initializeParams(d, N)\n",
    "weightMatrices = [A, B, C, W]\n",
    "print(W.shape.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the computational step\n",
    "# Given input matrix X, query q, and weight matrices, we perform a computational step,\n",
    "# also known as a \"hop\". Let M be the number of sentences\n",
    "def hopComputation(X, q, A, B, C, W):\n",
    "    #m_i = Ax_i\n",
    "    mem_matrix = A.dot(X) #dimension (dxN) x (Nx(NxR)) = dx(N*R)\n",
    "    #u = Bq\n",
    "    u = B.dot(q) #dimension (dx(N+R)) x ((N+R)xnumQ) = dxnumQ\n",
    "    #p_i = softmax(u^T m_i)\n",
    "    probs = T.nnet.softmax(u.T.dot(mem_matrix)) #dimension(numQxd)x(dx(N*R)) = numQx(N*R)\n",
    "    #C_i = Cx_i\n",
    "    c = C.dot(X) #dimension (dxN) x (Nx(NxR)) = dx(N*R)\n",
    "    o = c.dot(probs.T) #dimension (dx(N*R))x((N*R)xnumQ) = dxnumQ\n",
    "    \n",
    "    #w_embedded = Wo\n",
    "    w_embedded = W.dot(o).T #dimension (5xd)x(dxnumQ) = 5xnumQ.T = numQx5\n",
    "    \n",
    "    result = T.nnet.softmax(w_embedded)\n",
    "    return result\n",
    "    \n",
    "    #output = sum of c_matrix * probs\n",
    "#     o = (probs * c_embedded).sum(axis = 0)\n",
    "    #result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_hat = hopComputation(X, q, A, B, C, W)\n",
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "def inspect_inputs(i, node, fn):\n",
    "    print(i, node, \"input(s) value(s):\", fn.inputs, end='')\n",
    "\n",
    "def inspect_outputs(i, node, fn):\n",
    "    print(\" output(s) value(s):\", fn.outputs)\n",
    "    \n",
    "def detect_nan(i, node, fn):\n",
    "    for output in fn.outputs:\n",
    "        if (not isinstance(output[0], np.random.RandomState) and\n",
    "            np.isnan(output[0]).any()):\n",
    "            print('*** NaN detected ***')\n",
    "            theano.printing.debugprint(node)\n",
    "            print('Inputs : %s' % [input[0] for input in fn.inputs])\n",
    "            print('Outputs: %s' % [output[0] for output in fn.outputs])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Learning rate (chosen to be 0.01)\n",
    "epsilon = 0.4\n",
    "\n",
    "# This function trains our neural net, using stochastic gradient descent.\n",
    "def train_MemNN(loss, X, q, y, y_hat):\n",
    "    update_weights = []\n",
    "    for weightMatrix in weightMatrices:\n",
    "        update = T.grad(loss, weightMatrix)\n",
    "        update_weights.append((weightMatrix, weightMatrix - update * epsilon))\n",
    "    train_MemNN_func = theano.function(inputs=[X,q,y], outputs=[loss,y_hat], updates=update_weights, \n",
    "                        mode=theano.compile.MonitorMode(\n",
    "#                             pre_func=inspect_inputs,\n",
    "                            post_func=detect_nan))\n",
    "    return train_MemNN_func\n",
    "\n",
    "train_MemNN_func = train_MemNN(loss, X, q, y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(in_vect, question, answers, epochs=100):\n",
    "    train_errors = []\n",
    "    y_hats = []\n",
    "    for i in xrange(epochs):\n",
    "        error = 0\n",
    "        [cur_loss, cur_yhat] = train_MemNN_func(in_vect, question, answers)\n",
    "        error += cur_loss\n",
    "#         print(error)\n",
    "        train_errors.append(error)\n",
    "        y_hats.append(cur_yhat)\n",
    "    return [train_errors, y_hats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6094239725397508, 1.6094234496784199, 1.6094229268016771, 1.6094224039085616, 1.6094218809981129, 1.6094213580693701, 1.6094208351213721, 1.6094203121531585, 1.609419789163768, 1.6094192661522402, 1.6094187431176141, 1.6094182200589289, 1.6094176969752227, 1.6094171738655361, 1.6094166507289067, 1.6094161275643737, 1.609415604370976, 1.6094150811477532, 1.6094145578937424, 1.6094140346079839, 1.6094135112895154, 1.609412987937376, 1.6094124645506038, 1.6094119411282373, 1.6094114176693153, 1.6094108941728758, 1.6094103706379568, 1.6094098470635969, 1.6094093234488345, 1.6094087997927067, 1.6094082760942521, 1.6094077523525088, 1.609407228566514, 1.6094067047353056, 1.6094061808579212, 1.6094056569333983, 1.6094051329607746, 1.6094046089390874, 1.6094040848673734, 1.6094035607446706, 1.6094030365700156, 1.6094025123424449, 1.609401988060996, 1.6094014637247054, 1.6094009393326096, 1.6094004148837453, 1.6093998903771487, 1.6093993658118559, 1.6093988411869038, 1.6093983165013275, 1.6093977917541635, 1.6093972669444474, 1.6093967420712145, 1.6093962171335012, 1.6093956921303418, 1.6093951670607725, 1.6093946419238279, 1.6093941167185426, 1.6093935914439523, 1.6093930660990914, 1.6093925406829941, 1.609392015194695, 1.6093914896332282, 1.6093909639976276, 1.609390438286928, 1.6093899125001621, 1.6093893866363642, 1.6093888606945672, 1.6093883346738049, 1.6093878085731106, 1.6093872823915163, 1.6093867561280555, 1.6093862297817605, 1.6093857033516634, 1.6093851768367979, 1.6093846502361937, 1.6093841235488846, 1.6093835967739014, 1.6093830699102765, 1.6093825429570396, 1.6093820159132235, 1.6093814887778581, 1.6093809615499743, 1.6093804342286024, 1.6093799068127734, 1.609379379301517, 1.6093788516938632, 1.6093783239888411, 1.6093777961854814, 1.6093772682828125, 1.6093767402798633, 1.6093762121756634, 1.6093756839692408, 1.6093751556596245, 1.6093746272458418, 1.6093740987269212, 1.6093735701018903, 1.6093730413697769, 1.6093725125296079, 1.6093719835804101]\n",
      "[[ 0.20005041  0.19999227  0.200042    0.19998987  0.19992545]\n",
      " [ 0.20005823  0.19999751  0.20004325  0.19998166  0.19991935]\n",
      " [ 0.20005041  0.19999227  0.200042    0.19998987  0.19992545]\n",
      " [ 0.20005577  0.19999229  0.20004185  0.19998651  0.19992359]\n",
      " [ 0.2000556   0.19999329  0.20003551  0.19999057  0.19992504]\n",
      " [ 0.20005874  0.19999507  0.20004755  0.19998472  0.19991392]\n",
      " [ 0.20005077  0.19999117  0.20003729  0.19998874  0.19993203]\n",
      " [ 0.20005024  0.19999645  0.20004954  0.19998924  0.19991453]]\n",
      "[[0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "in_vect = tensor_stack.astype(int)\n",
    "question = train_Q.astype(int)\n",
    "answers = np.array([np.array([0,0,0,0,1]),\n",
    "                    np.array([0,0,0,1,0]),\n",
    "                    np.array([0,1,0,0,0]),\n",
    "                    np.array([1,0,0,0,0]),\n",
    "                    np.array([1,0,0,0,0]),\n",
    "                    np.array([0,0,1,0,0]),\n",
    "                    np.array([1,0,0,0,0]),\n",
    "                    np.array([0,1,0,0,0])\n",
    "                   ]).astype(int)\n",
    "\n",
    "# print(in_vect)\n",
    "# print(question)\n",
    "# print(answers)\n",
    "# print(type(in_vect[0][0]))\n",
    "[train_errors, y_hats] = train_model(in_vect, question, answers)\n",
    "print(train_errors)\n",
    "print(y_hats[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
