{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numQuestions  2\n",
      "[[u'The example in lines 4-8 primarily suggests that', u\"Balzac's work was not especially popular among female readers\", u'Balzac could not write convincingly about financial matters', u\"Balzac's insights into character were not evident in his everyday life\", u'people who knew Balzac personally could not respect him as an artist', u'readers had unreasonable expectation of Balzac the man'], [u\"The author mentions Balzac's experience as a schoolboy in order to\", u'explain why Balzac was unable to conduct his financial affairs properly', u\"point out a possible source of Balzac's powerful imagination\", u\"exonerate the boarding school for Balzac's lackluster performance\", u'foster the impression that Balzac was an unruly student', u\"depict the conditions of boarding school life during Balzac's youth\"]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from triple_reader import triple_reader\n",
    "# from question_reader_utf16 import question_reader\n",
    "from question_reader_utf8 import question_reader\n",
    "from gensim.models import word2vec\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "\n",
    "# initialize word2vec model\n",
    "word_model = word2vec.Word2Vec.load_word2vec_format('word2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/\"\n",
    "    \"Senior Thesis Code/ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/4/Triples/4-long2.txt\")\n",
    "\n",
    "q_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/Senior Thesis Code/\"\n",
    "\"ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/4/4-long2-q.txt\")\n",
    "\n",
    "a_file = (\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/Senior Thesis Code/\"\n",
    "\"ModifiedEntityGraph/prod/MCTest/production/MCTest/OCR_text/4/4-long2-a.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in file as tensors\n",
    "\n",
    "tr = triple_reader(text_file)\n",
    "# print tr.tripleList\n",
    "tensor = tr.tensor\n",
    "\n",
    "enMap = tr.enMap\n",
    "relMap = tr.relMap\n",
    "\n",
    "R = len(tensor)\n",
    "N = len(tensor[0])\n",
    "# dimension for encoding is arbitrary, we pick 20 here\n",
    "d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 4150)\n",
      "83 4150\n"
     ]
    }
   ],
   "source": [
    "tensor_stack = np.hstack(tuple(tensor))\n",
    "print(tensor_stack.shape)\n",
    "print(N, N*R)\n",
    "\n",
    "X = T.lmatrix('X')\n",
    "q = T.lmatrix('q')\n",
    "y = T.lmatrix('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('took', 0.5837877883692939, False, 'went'), ('wife', 0.19713489972182308, True, 'boat')]\n"
     ]
    }
   ],
   "source": [
    "# Find the word in entity that's most similar to given word\n",
    "# default topsim to lowest possible python int\n",
    "def findSimEn(word):\n",
    "    topsim = None\n",
    "    topEn = None\n",
    "    for en in enMap:\n",
    "        if type(en) == int:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word_model.similarity(en, word)\n",
    "        except KeyError as e:\n",
    "            sim = None\n",
    "        if sim > topsim:\n",
    "            topsim = sim\n",
    "            topEn = en\n",
    "    return [topEn, topsim]\n",
    "\n",
    "def findSimRel(word):\n",
    "    topsim = None\n",
    "    topRel = None\n",
    "    for rel in relMap:\n",
    "        if type(rel) == int:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word_model.similarity(rel, word)\n",
    "        except KeyError as e:\n",
    "            sim = None\n",
    "        if sim > topsim:\n",
    "            topsim = sim\n",
    "            topRel = rel\n",
    "    return [topRel, topsim]\n",
    "\n",
    "# print findSimEn('critic')\n",
    "# print findSimRel('go')\n",
    "\n",
    "# Return top similarity, sim score, and isEn boolean\n",
    "def findTopEnOrRel(word):\n",
    "#     try:\n",
    "    [topEn, topEnsim] = findSimEn(word)\n",
    "    [topRel, topRelsim] = findSimRel(word)\n",
    "    if topEnsim > topRelsim:\n",
    "        return (topEn, topEnsim, True, word)\n",
    "    else:\n",
    "        return (topRel, topRelsim, False, word)\n",
    "        \n",
    "    # if can't find similarity, ignore it\n",
    "#     except KeyError as e:\n",
    "#         return [None, 0, False, word]\n",
    "    \n",
    "# Return top 2 sims for an array of words\n",
    "def findTopEnOrRelArr(wordArr):\n",
    "    topArrs = []\n",
    "    for word in wordArr:\n",
    "        top = findTopEnOrRel(word)\n",
    "#         print top\n",
    "        topArrs.append(top)\n",
    "#     print topArrs\n",
    "#     print topArrs\n",
    "    sortedTop = sorted(topArrs, key=lambda x: -x[1] if x[1] is not None else sys.maxint)\n",
    "#     print sortedTop\n",
    "    top1 = sortedTop[0]\n",
    "    top2 = None\n",
    "    # if the top is a relation, we have to pick an entity\n",
    "    if top1[2] == False:\n",
    "        curIndex = 1\n",
    "        while curIndex < len(sortedTop):\n",
    "            cur = sortedTop[curIndex]\n",
    "            if cur[2] == False:\n",
    "                curIndex += 1\n",
    "                continue\n",
    "            else:\n",
    "                top2 = cur\n",
    "                break\n",
    "    else:\n",
    "        top2 = sortedTop[1]\n",
    "    if top2 == None:\n",
    "        top2 = [0, 0, True]\n",
    "    return [top1, top2]\n",
    "\n",
    "print(findTopEnOrRelArr([\"critic\", \"went\", \"hi\", \"boat\", \"paint\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numQuestions  13\n",
      "[('legislation', 0.48723350755038292, True, u'passage'), ('call', 0.34856425054760332, True, u'information')]\n",
      "[('name', 0.39348277679045962, True, u'word'), ('year', 0.36010884827987122, True, u'nearly')]\n",
      "[('Douglass', 1.0, True, u'Douglass'), ('newspapers', 0.77920511690145189, True, u'newspaper')]\n",
      "[('Anthony', 0.99999999999999978, True, u'Anthony'), ('which', 0.59336037338987069, True, u'The')]\n",
      "[('rights', 1.0, True, u'rights'), ('Douglass', 1.0, True, u'Douglass')]\n",
      "[('name', 0.37368623494200653, True, u'phrase'), ('year', 0.36010884827987122, True, u'nearly')]\n",
      "[('legislation', 0.48723350755038292, True, u'passage'), ('she', 0.35612284914044162, True, u'Lucy')]\n",
      "[('Douglass', 1.0, True, u'Douglass'), ('Douglas', 1.0, True, u'Douglas')]\n",
      "[('Douglass', 1.0, True, u'Douglass'), ('it', 0.49405084764469454, True, u'probably')]\n",
      "[('rights', 1.0, True, u'rights'), ('Women', 0.50650276309085007, True, u\"Women's\")]\n",
      "[('accepted', 0.45454538992104898, False, u'presented'), ('He', 0.42082288537972068, True, u'As')]\n",
      "[('rights', 1.0, True, u'rights'), ('which', 0.59336037338987069, True, u'The')]\n",
      "[('Douglass', 1.0, True, u'Douglass'), ('advocated', 0.62694799218254871, False, u'opposed')]\n",
      "(133, 8)\n",
      "(133, 5)\n"
     ]
    }
   ],
   "source": [
    "qr = question_reader(q_file)\n",
    "\n",
    "# print qr.numQuestions\n",
    "\n",
    "numTrainQ = int(qr.numQuestions*(float(2)/3))\n",
    "numTestQ = qr.numQuestions - numTrainQ\n",
    "# print numTrainQ\n",
    "# print numTestQ\n",
    "\n",
    "CHOICES_PER_Q = 5\n",
    "\n",
    "train_Q = []\n",
    "test_Q = []\n",
    "# VECTORIZE BY FINDING TOP TWO SIMILAR TO EACH QUESTION, AND MAKING A 2-HOT VECTOR OF LENGTH N+R\n",
    "questions = qr.questionCombos\n",
    "for i in xrange(qr.numQuestions):\n",
    "    question = questions[i]\n",
    "    question_words = question[0].split(\" \")\n",
    "    # remove stopwords\n",
    "    question_words = [word for word in question_words if word not in stopwords.words('english')]\n",
    "    [top1, top2] = findTopEnOrRelArr(question_words)\n",
    "    print([top1, top2])\n",
    "    \n",
    "    # if word in question doesn't match, move on\n",
    "    if top1[0] == None:\n",
    "        continue\n",
    "    \n",
    "    # Now vectorize it to be of length N+R\n",
    "    if top1[2] == True:\n",
    "        index1 = enMap[top1[0]]\n",
    "    else:\n",
    "        index1 = N + relMap[top1[0]]\n",
    "    if top2[2] == True:\n",
    "        index2 = enMap[top2[0]]\n",
    "    else:\n",
    "        index2 = N + relMap[top2[0]]\n",
    "    curQVec = np.zeros(N+R)\n",
    "    curQVec[index1] = 1\n",
    "    curQVec[index2] = 1\n",
    "    if i < numTrainQ:\n",
    "        train_Q.append(curQVec)\n",
    "    else:\n",
    "        test_Q.append(curQVec)\n",
    "train_Q = np.array(train_Q)\n",
    "train_Q = train_Q.T\n",
    "test_Q = np.array(test_Q)\n",
    "test_Q = test_Q.T\n",
    "print(train_Q.shape)\n",
    "print(test_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a weight matrix of given size. \n",
    "# The matrix is initialized randomly with Gaussian distribution \n",
    "# with mean=0 and \\sigma=0.1\n",
    "def initializeWeightMatrix(in_size, out_size):\n",
    "    return theano.shared(0.1 * np.random.randn(in_size, out_size))\n",
    "\n",
    "# Create a bias vector of all zeros of given size\n",
    "def initializeBiasVector(size):\n",
    "    return theano.shared(np.zeros(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20]\n"
     ]
    }
   ],
   "source": [
    "# Initialize all our parameters, given our dimensions.\n",
    "# Input matrix has shape Nx(N*R)\n",
    "# Query matrix has shape 5xnumQ\n",
    "# A is the first matrix used to embed our input. It has size dxN\n",
    "# B is the matrix used to embed the query. It has size dx(N+R)\n",
    "# C is the next matrix used to embed our input. It has size dxN\n",
    "# W is the final matrix. Takes output O and produces result w_embedded. It has size 5xd\n",
    "# R is a matrix used to make the dimensions match from prior_Result. it has size dx5\n",
    "\n",
    "def initializeParams(d, N):\n",
    "    A = initializeWeightMatrix(d,N)\n",
    "    B = initializeWeightMatrix(d,N+R)\n",
    "    C = initializeWeightMatrix(d,N)\n",
    "    W = initializeWeightMatrix(CHOICES_PER_Q,d)\n",
    "    \n",
    "#     A = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     B = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     C = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     W = theano.shared(initializeWeightMatrix(V, d))\n",
    "    return A, B, C, W\n",
    "\n",
    "A, B, C, W = initializeParams(d, N)\n",
    "weightMatrices = [A, B, C, W]\n",
    "print(W.shape.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the computational step\n",
    "# Given input matrix X, query q, and weight matrices, we perform a computational step,\n",
    "# also known as a \"hop\". Let M be the number of sentences.\n",
    "# prior_result has dim dxnumQ\n",
    "def hopComputation(prior_result, X, A, B, C):\n",
    "    #m_i = Ax_i\n",
    "    mem_matrix = A.dot(X) #dimension (dxN) x (Nx(NxR)) = dx(N*R)\n",
    "    #u = Bq\n",
    "#     u = B.dot(q) #dimension (dx(N+R)) x ((N+R)xnumQ) = dxnumQ\n",
    "#     u = R.dot(prior_result.T) #dimension(dx5)x(5xnumQ) = dxnumQ\n",
    "    u = prior_result\n",
    "    #p_i = softmax(u^T m_i)\n",
    "    probs = T.nnet.softmax(u.T.dot(mem_matrix)) #dimension(numQxd)x(dx(N*R)) = numQx(N*R)\n",
    "    #C_i = Cx_i\n",
    "    c = C.dot(X) #dimension (dxN) x (Nx(NxR)) = dx(N*R)\n",
    "    o = c.dot(probs.T) #dimension (dx(N*R))x((N*R)xnumQ) = dxnumQ\n",
    "    \n",
    "    #w_embedded = Wo\n",
    "#     w_embedded = W.dot(o).T #dimension (5xd)x(dxnumQ) = 5xnumQ.T = numQx5\n",
    "    \n",
    "#     result = T.nnet.softmax(w_embedded)\n",
    "#     return w_embedded\n",
    "    return o + u\n",
    "    \n",
    "    #output = sum of c_matrix * probs\n",
    "#     o = (probs * c_embedded).sum(axis = 0)\n",
    "    #result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_value = B.dot(q) #dimension dxnumQ\n",
    "hops_result, updates = theano.scan(fn=hopComputation,\n",
    "                                   n_steps=10,\n",
    "                                   outputs_info=initial_value,\n",
    "                                   non_sequences=[X] + [A,B,C],\n",
    "                                   )\n",
    "real_hops_result = hops_result[-1] #dimension dxnumQ\n",
    "# Do W.dot(final_result)\n",
    "w_embedded = W.dot(real_hops_result).T #dimension (5xd)x(dxnumQ) = 5xnumQ.T = numQx5\n",
    "y_hat = T.nnet.softmax(w_embedded)\n",
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "def inspect_inputs(i, node, fn):\n",
    "    print(i, node, \"input(s) value(s):\", fn.inputs, end='')\n",
    "\n",
    "def inspect_outputs(i, node, fn):\n",
    "    print(\" output(s) value(s):\", fn.outputs)\n",
    "    \n",
    "def detect_nan(i, node, fn):\n",
    "    for output in fn.outputs:\n",
    "        if (not isinstance(output[0], np.random.RandomState) and\n",
    "            np.isnan(output[0]).any()):\n",
    "            print('*** NaN detected ***')\n",
    "            theano.printing.debugprint(node)\n",
    "            print('Inputs : %s' % [input[0] for input in fn.inputs])\n",
    "            print('Outputs: %s' % [output[0] for output in fn.outputs])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning rate (chosen to be 0.01)\n",
    "epsilon = 0.01\n",
    "\n",
    "# This function trains our neural net, using stochastic gradient descent.\n",
    "def train_MemNN(loss, X, q, y, y_hat):\n",
    "    update_weights = []\n",
    "    for weightMatrix in weightMatrices:\n",
    "        update = T.grad(loss, weightMatrix)\n",
    "        update_weights.append((weightMatrix, weightMatrix - update * epsilon))\n",
    "    train_MemNN_func = theano.function(inputs=[X,q,y], outputs=[loss,y_hat], updates=update_weights, \n",
    "                        mode=theano.compile.MonitorMode(\n",
    "#                             pre_func=inspect_inputs,\n",
    "                            post_func=detect_nan))\n",
    "    return train_MemNN_func\n",
    "\n",
    "train_MemNN_func = train_MemNN(loss, X, q, y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(in_vect, question, answers, epochs=100):\n",
    "    train_errors = []\n",
    "    y_hats = []\n",
    "    for i in xrange(epochs):\n",
    "        error = 0\n",
    "        [cur_loss, cur_yhat] = train_MemNN_func(in_vect, question, answers)\n",
    "        error += cur_loss\n",
    "#         print(error)\n",
    "        train_errors.append(error)\n",
    "        y_hats.append(cur_yhat)\n",
    "    return [train_errors, y_hats]\n",
    "\n",
    "def test_model(in_vect, question):\n",
    "    # use a stub answers matrix, it doesn't really matter\n",
    "    print(question.shape)\n",
    "    [loss, y_hat] = train_MemNN_func(in_vect, question, np.zeros((len(question[0]), 5)).astype(int))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 4150)\n",
      "(133, 8)\n",
      "(13, 5)\n",
      "(8, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "(133, 5)\n",
      "['C', 'B', 'E', 'A', 'D']\n",
      "['E', 'B', 'D', 'D', 'D']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "in_vect = tensor_stack.astype(int)\n",
    "question = train_Q.astype(int)\n",
    "\n",
    "def letterToArr(letter):\n",
    "    if letter == 'A':\n",
    "        return np.array([1,0,0,0,0])\n",
    "    elif letter == 'B':\n",
    "        return np.array([0,1,0,0,0])\n",
    "    elif letter == 'C':\n",
    "        return np.array([0,0,1,0,0])\n",
    "    elif letter == 'D':\n",
    "        return np.array([0,0,0,1,0])\n",
    "    elif letter == 'E':\n",
    "        return np.array([0,0,0,0,1])\n",
    "\n",
    "def convArrToArrs(arr):\n",
    "    anz = []\n",
    "    for i in xrange(len(arr)):\n",
    "        anz.append(letterToArr(arr[i]))\n",
    "    return np.array(anz)\n",
    "\n",
    "\n",
    "az = open(a_file, \"r\")\n",
    "anwz = []\n",
    "for line in az:\n",
    "    anwz.append(line.strip())\n",
    "answers = convArrToArrs(anwz).astype(int)\n",
    "train_ans = answers[:numTrainQ]\n",
    "test_ans = anwz[numTrainQ:]\n",
    "# print(answers)\n",
    "\n",
    "# long1 = np.array([np.array([0,1,0,0,0]),\n",
    "#                   np.array([1,0,0,0,0]),\n",
    "#                   np.array([0,0,0,1,0]),\n",
    "#                   np.array([0,0,0,0,1]),\n",
    "#                   np.array([1,0,0,0,0]),\n",
    "#                   np.array([1,0,0,0,0]),\n",
    "#                   np.array([0,0,0,1,0]),\n",
    "#                   np.array([0,0,0,1,0])\n",
    "#                   ]).astype(int)\n",
    "\n",
    "# print(in_vect)\n",
    "# print(question)\n",
    "# print(answers)\n",
    "# print(type(in_vect[0][0]))\n",
    "\n",
    "print(in_vect.shape)\n",
    "print(question.shape)\n",
    "print(answers.shape)\n",
    "print(train_ans.shape)\n",
    "# print(test_ans.shape)\n",
    "\n",
    "num_iterations = 20\n",
    "num_per_iter = 50\n",
    "bestAns = []\n",
    "mostCorrect = -1\n",
    "for i in xrange(num_iterations):\n",
    "    [train_errors, y_hats] = train_model(in_vect, question, train_ans, num_per_iter)\n",
    "    res = test_model(in_vect, test_Q.astype(int))\n",
    "#     print(res)\n",
    "    predictions = []\n",
    "    for ans in res:\n",
    "        ind = np.argmax(ans)\n",
    "        choice = None\n",
    "        if ind == 0:\n",
    "            choice = 'A'\n",
    "        elif ind == 1:\n",
    "            choice = 'B'\n",
    "        elif ind == 2:\n",
    "            choice = 'C'\n",
    "        elif ind == 3:\n",
    "            choice = 'D'\n",
    "        elif ind == 4:\n",
    "            choice = 'E'\n",
    "        else:\n",
    "            print('CANT GET HERE OHASDIIADSF')\n",
    "        predictions.append(choice)\n",
    "    numCorrect = 0\n",
    "    for i in xrange(len(predictions)):\n",
    "        if predictions[i] == test_ans[i]:\n",
    "            numCorrect += 1\n",
    "    if numCorrect > mostCorrect:\n",
    "        mostCorrect = numCorrect\n",
    "        bestAns = predictions\n",
    "    \n",
    "# print(train_errors)\n",
    "# print(y_hats[-1])\n",
    "print(test_ans)\n",
    "print(bestAns)\n",
    "print(mostCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
