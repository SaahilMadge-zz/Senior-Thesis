{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse\n",
    "\n",
    "def special_hstack((a, b)):\n",
    "    if a.shape[1] == 0:\n",
    "        return b\n",
    "    elif b.shape[1] == 0:\n",
    "        return a\n",
    "    else:\n",
    "        return scipy.sparse.hstack((a, b))\n",
    "    \n",
    "def special_vstack((a, b)):\n",
    "    if a.shape[0] == 0:\n",
    "        return b\n",
    "    elif b.shape[0] == 0:\n",
    "        return a\n",
    "    else:\n",
    "        return scipy.sparse.vstack((a, b))\n",
    "\n",
    "# This will be a class to read in + format sentences from bAbl tasks\n",
    "#class vectorize_bAbl_task:\n",
    "\n",
    "class VectorizeTask:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.readFile()\n",
    "        self.bagOfWords()\n",
    "        self.createInputMatrices()\n",
    "    \n",
    "    def readFile(self):\n",
    "        f_train = open(self.filename + \"_train.txt\")\n",
    "        \n",
    "        # Add each sentence in the story to the set of stories, resetting when ID hits 1\n",
    "        self.stories = []\n",
    "        cur_story = []\n",
    "        for line in f_train:\n",
    "            split_line = line.split(' ',1)\n",
    "            ID = split_line[0]\n",
    "            if (int(ID) == 1):\n",
    "                self.stories.append(cur_story)\n",
    "                cur_story = []\n",
    "            cur_story.append(split_line[1].lower())\n",
    "        # append the last line, remove the blank at the beginning. Remove numbers\n",
    "        self.stories.append(cur_story)\n",
    "        self.stories = self.stories[1:]\n",
    "        self.stories = map(lambda x: map(lambda y: re.sub(\"\\d\", \"\", y), x), self.stories)\n",
    "    \n",
    "    def printStory(self):\n",
    "        print self.stories\n",
    "        \n",
    "    def bagOfWords(self):\n",
    "        vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor=None, \n",
    "                                     stop_words=None,max_features=5000)\n",
    "        combinedSentences = [' '.join([sentence for story in self.stories for sentence in story])]\n",
    "        train_data_features = vectorizer.fit_transform(combinedSentences)\n",
    "#         train_data_features = vectorizer.fit_transform([story for story in self.stories])\n",
    "#         print self.stories[0]\n",
    "#         print vectorizer.get_feature_names()\n",
    "#         print train_data_features\n",
    "#         print '--------'\n",
    "        self.num_words = len(vectorizer.get_feature_names())\n",
    "        self.vectorizer = vectorizer\n",
    "        self.train_data_features= train_data_features\n",
    "        \n",
    "    def createInputMatrices(self):\n",
    "        text_question_pairs = []\n",
    "        for story in self.stories:\n",
    "            text = \"\"\n",
    "            textMatrix = scipy.sparse.random(0, self.num_words)\n",
    "            # If it's not a question, just add it to the text. We are just performing one-hot encoding\n",
    "            # on each sentence anyway\n",
    "            for sentence in story:\n",
    "#                 print sentence\n",
    "                if \"?\" not in sentence:\n",
    "                    text += sentence\n",
    "                    transformedSentence = self.vectorizer.transform([sentence])\n",
    "                    textMatrix = special_vstack((textMatrix, transformedSentence))\n",
    "                else:\n",
    "                    split_q = sentence.rsplit(' ', 1)\n",
    "                    query = split_q[0]\n",
    "                    \n",
    "                    # NOTE: FOR THEANO ONE-HOT ENCODING, YOU HAVE ONLY 1 ELEMENT PER ROW, with the value\n",
    "                    # representing the index (0-18) of the 1\n",
    "                    # So [0,0,1,...0] should be [2] b/c the 1 is at index 2\n",
    "                    answer = split_q[1]\n",
    "                    q_vector = self.vectorizer.transform([query]).toarray()\n",
    "                    # we do a first 0 to get the first row of the 2d array, then we have to do\n",
    "                    # np.where, which returns a tuple with an array, so we need to index by 0\n",
    "                    # again\n",
    "                    transformed_answer = self.vectorizer.transform([answer]).toarray()[0]\n",
    "                    assert np.sum(transformed_answer) == 1\n",
    "#                     print 'here'\n",
    "#                     print transformed_answer\n",
    "#                     print np.where(transformed_answer == 1)[0][0]\n",
    "                    a_vector = np.array([np.where(transformed_answer == 1)[0][0]])\n",
    "                    text_question_pairs.append({\"question\": q_vector, \"answer\": a_vector,\n",
    "                                                \"text\": textMatrix.toarray(),\n",
    "                                                \"original_question\": query, \"original_answer\": answer,\n",
    "                                                \"original_text\": text})\n",
    "        self.text_question_pairs = text_question_pairs\n",
    "#         print text_question_pairs\n",
    "#         print text_question_pairs[0][\"text\"]\n",
    "#         print text_question_pairs[0]\n",
    "#         print text_question_pairs[0][\"original_question\"]\n",
    "#         print text_question_pairs[0][\"text\"]\n",
    "    \n",
    "    def getTextQuestionPairs(self):\n",
    "        return self.text_question_pairs\n",
    "    \n",
    "    def getVectorizer(self):\n",
    "        return self.vectorizer\n",
    "    \n",
    "    def getNumWords(self):\n",
    "        return len(self.vectorizer.vocabulary_)\n",
    "    \n",
    "    def getNumTrainingExamples(self):\n",
    "        return len(self.text_question_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_text': 'mary moved to the bathroom.\\njohn went to the hallway.\\n', 'text': array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]]), 'question': array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]]), 'original_answer': '\\tbathroom\\t\\n', 'original_question': 'where is mary?', 'answer': array([1])}\n",
      "{'original_text': 'mary moved to the bathroom.\\njohn went to the hallway.\\ndaniel went back to the hallway.\\nsandra moved to the garden.\\n', 'text': array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
      "       [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0]]), 'question': array([[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]), 'original_answer': '\\thallway\\t\\n', 'original_question': 'where is daniel?', 'answer': array([5])}\n"
     ]
    }
   ],
   "source": [
    "task = VectorizeTask(\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/Data/tasks_1-20_v1-2/en/qa1_single-supporting-fact\")\n",
    "qaPairs = task.getTextQuestionPairs()\n",
    "print qaPairs[0]\n",
    "print qaPairs[1]\n",
    "# print type(qaPairs[0][\"text\"])\n",
    "# print qaPairs[0][\"text\"]\n",
    "# print qaPairs[0][\"question\"]\n",
    "# print qaPairs[0][\"answer\"]\n",
    "# print task.getNumWords()\n",
    "# print task.getNumTrainingExamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
