{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fbTaskReader as taskReader\n",
    "reload(taskReader)\n",
    "\n",
    "# Get the input matrices for the facebook tasks\n",
    "taskFilePaths = [\"/Users/SaahilM/Documents/Princeton/Academics/Thesis/Data/tasks_1-20_v1-2/en/qa1_single-supporting-fact\"]\n",
    "task1 = taskReader.VectorizeTask(taskFilePaths[0])\n",
    "qaPairs = task1.getTextQuestionPairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 19 20\n"
     ]
    }
   ],
   "source": [
    "# theano.config.compute_test_value = 'warn'\n",
    "\n",
    "# Number of training examples\n",
    "N = task1.getNumTrainingExamples()\n",
    "# Number of words in our dictionary\n",
    "V = task1.getNumWords()\n",
    "# Dimension to encode our information. They use 20 for independent training\n",
    "d = 20\n",
    "\n",
    "print(N,V,d)\n",
    "\n",
    "# Input X is the collection of sentences, Vx(text_length) matrix\n",
    "# Input q is our query, a vector of size Vx1\n",
    "# The actual result is y, a vector of size Vx1\n",
    "X = T.lmatrix('X')\n",
    "q = T.lrow('q')\n",
    "y = T.lvector('y')\n",
    "\n",
    "X.tag.test_value = np.zeros((2, V), dtype=np.int64)\n",
    "q.tag.test_value = np.zeros((2,V), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a weight matrix of given size. \n",
    "# The matrix is initialized randomly with Gaussian distribution \n",
    "# with mean=0 and \\sigma=0.1\n",
    "def initializeWeightMatrix(in_size, out_size):\n",
    "    return theano.shared(np.random.randn(in_size, out_size))\n",
    "\n",
    "# Create a bias vector of all zeros of given size\n",
    "def initializeBiasVector(size):\n",
    "    return theano.shared(np.zeros(size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, False)\n"
     ]
    }
   ],
   "source": [
    "# Initialize all our parameters, given our dimensions.\n",
    "# A is the first matrix used to embed our input. It has size Vxd\n",
    "# B is the matrix used to embed the query. It has size Vxd\n",
    "# C is the next matrix used to embed our input. It has size Vxd\n",
    "# W is the final matrix. Takes output O and produces result R. It has size dxV\n",
    "# H is the linear mapping we apply to u_i in each layer, since we have set it\n",
    "#      up like an RNN\n",
    "def initializeParams(d, V):\n",
    "    A = initializeWeightMatrix(V, d)\n",
    "    B = initializeWeightMatrix(V, d)\n",
    "    C = initializeWeightMatrix(V, d)\n",
    "    W = initializeWeightMatrix(d, V)\n",
    "    H = initializeWeightMatrix(d, d) #H is just a vector\n",
    "    \n",
    "#     A = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     B = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     C = theano.shared(initializeWeightMatrix(d, V))\n",
    "#     W = theano.shared(initializeWeightMatrix(V, d))\n",
    "    return A, B, C, W, H\n",
    "\n",
    "A, B, C, W, H = initializeParams(d, V)\n",
    "weightMatrices = [A, B, C, W, H]\n",
    "# for weightMatrix in weightMatrices:\n",
    "#     print weightMatrix.eval()\n",
    "# print(theano.shared(np.zeros((1,V), dtype=np.int64)).dot(B).shape.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the computational step\n",
    "# Given input matrix X, query q, and weight matrices, we perform a computational step,\n",
    "# also known as a \"hop\". Let M be the number of sentences\n",
    "def hopComputation(prior_result, X, A, B, C, W, H):\n",
    "    # m_i = Ax_i\n",
    "    mem_matrix = X.dot(A) #dimension (MxV)x(Vxd) = Mxd\n",
    "    \n",
    "    u = prior_result\n",
    "    \n",
    "    # p_i = softmax(u^T m_i)\n",
    "    probs = T.nnet.softmax(mem_matrix.dot(u.T)) #dimension (Mxd)x(dx1) = Mx1\n",
    "    \n",
    "    # C_i = Cx_i\n",
    "    c_embedded = X.dot(C) #dimension (MxV)x(Vxd) = Mxd\n",
    "    # output = sum of c_matrix * probs\n",
    "    o = (probs * c_embedded).sum(axis = 0) #dimension = 1xd\n",
    "    o = o.dimshuffle('x', 0)\n",
    "    o = T.unbroadcast(o, 0)\n",
    "    \n",
    "    layer_result = o + u.dot(H) #dimension 1xd\n",
    "#     layer_result = T.unbroadcast(layer_result, 1)\n",
    "    \n",
    "    print(prior_result.ndim)\n",
    "    print(u.ndim)\n",
    "    print(mem_matrix.ndim)\n",
    "    print(probs.ndim)\n",
    "    print(c_embedded.ndim)\n",
    "    print(o.ndim)\n",
    "    print(layer_result.ndim)\n",
    "    \n",
    "    print(prior_result.broadcastable)\n",
    "    print(u.broadcastable)\n",
    "    print(mem_matrix.broadcastable)\n",
    "    print(probs.broadcastable)\n",
    "    print(c_embedded.broadcastable)\n",
    "    print(o.broadcastable)\n",
    "    print(layer_result.broadcastable)\n",
    "    \n",
    "    return layer_result\n",
    "    #For each hop computation, we will return the layer_result vector. We will return a \n",
    "    # final result multiplied by vector W at the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "(False, False)\n",
      "(False, False)\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "(False, False)\n",
      "(False, False)\n",
      "(False, False)\n",
      "(False, False)\n",
      "(False, False)\n",
      "(False, False)\n",
      "(False, False)\n",
      "breaking\n",
      "3\n",
      "(False, False, False)\n",
      "2\n",
      "(False, False)\n",
      "2\n",
      "(False, False)\n"
     ]
    }
   ],
   "source": [
    "# Here we do the scan step 3 times (for our 3 hops)\n",
    "initial_value = q.dot(B)#.dimshuffle('x',0)\n",
    "print(initial_value.ndim)\n",
    "initial_value = T.unbroadcast(initial_value, 0)\n",
    "print (B.ndim)\n",
    "print(B.broadcastable)\n",
    "print(initial_value.broadcastable)\n",
    "hops_result, updates = theano.scan(fn=hopComputation,\n",
    "                                   n_steps=3,\n",
    "                                   outputs_info=initial_value,\n",
    "                                   non_sequences=[X] + weightMatrices,\n",
    "                                   )\n",
    "real_hops_result = hops_result[-1]\n",
    "print(\"breaking\")\n",
    "print(hops_result.ndim)\n",
    "print(hops_result.broadcastable)\n",
    "print(real_hops_result.ndim)\n",
    "print(real_hops_result.broadcastable)\n",
    "pre_softmax = real_hops_result.dot(W)\n",
    "y_hat = T.nnet.softmax(pre_softmax)\n",
    "print(y_hat.ndim)\n",
    "print(y_hat.broadcastable)\n",
    "# y_hat = T.unbroadcast(y_hat, 1)\n",
    "# y_hat = T.unbroadcast(y_hat, 0)\n",
    "# q.fill(theano.shared(np.random.randn(1,4)))\n",
    "# print q.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(False,)\n",
      "0\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "#Learning rate\n",
    "epsilon = 0.04\n",
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean()\n",
    "print(y.ndim)\n",
    "print(y.broadcastable)\n",
    "print(loss.ndim)\n",
    "print(loss.broadcastable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "def inspect_inputs(i, node, fn):\n",
    "    print(i, node, \"input(s) value(s):\", fn.inputs, end='')\n",
    "\n",
    "def inspect_outputs(i, node, fn):\n",
    "    print(\" output(s) value(s):\", fn.outputs)\n",
    "    \n",
    "def detect_nan(i, node, fn):\n",
    "    for output in fn.outputs:\n",
    "        if (not isinstance(output[0], np.random.RandomState) and\n",
    "            np.isnan(output[0]).any()):\n",
    "            print('*** NaN detected ***')\n",
    "            theano.printing.debugprint(node)\n",
    "            print('Inputs : %s' % [input[0] for input in fn.inputs])\n",
    "            print('Outputs: %s' % [output[0] for output in fn.outputs])\n",
    "            break\n",
    "\n",
    "# This function trains our neural net, using stochastic gradient descent.\n",
    "def train_MemNN(loss, X, q, y):\n",
    "    update_weights = []\n",
    "    for weightMatrix in weightMatrices:\n",
    "        update = T.grad(loss, weightMatrix)\n",
    "        update_weights.append((weightMatrix, weightMatrix - update * epsilon))\n",
    "    train_MemNN_func = theano.function(inputs=[X,q,y], outputs=loss, updates=update_weights, \n",
    "                        mode=theano.compile.MonitorMode(\n",
    "#                             pre_func=inspect_inputs,\n",
    "                            post_func=detect_nan))\n",
    "    return train_MemNN_func\n",
    "\n",
    "train_MemNN_func = train_MemNN(loss, X, q, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 19)\n",
      "(1, 19)\n",
      "(1,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[1] = 1, input[1].shape[1] = 20)\nApply node that caused the error: Elemwise{Mul}[(0, 0)](Softmax.0, <TensorType(float64, matrix)>)\nInputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]\n\nHINT: Use another linker then the c linker to have the inputs shapes and strides printed.\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,cpu,scan_fn}(TensorConstant{3}, IncSubtensor{InplaceSet;:int64:}.0, <TensorType(float64, matrix)>, dot.0, dot.0)\nInputs types: [TensorType(int8, scalar), TensorType(float64, 3D), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(float64, matrix)]\nInputs shapes: [(), (4, 1, 20), (20, 20), (2, 20), (2, 20)]\nInputs strides: [(), (160, 160, 8), (160, 8), (160, 8), (160, 8)]\nInputs values: [array(3, dtype=int8), 'not shown', 'not shown', 'not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-31474e4b3e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqaPairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-31474e4b3e42>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#             train_q = np.array(textQuestionPair[\"question\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#             train_y = np.array(textQuestionPair[\"answer\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_MemNN_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcur_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/gof/link.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    795\u001b[0m                     \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                     \u001b[0mraise_with_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthunk_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthunk_groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/gof/link.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthunk_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                     \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mraise_with_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/gof/link.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWrapLinker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/compile/monitormode.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, i, node, fn)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    670\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    659\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/SaahilM/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:3605)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/SaahilM/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:3537)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[1] = 1, input[1].shape[1] = 20)\nApply node that caused the error: Elemwise{Mul}[(0, 0)](Softmax.0, <TensorType(float64, matrix)>)\nInputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]\n\nHINT: Use another linker then the c linker to have the inputs shapes and strides printed.\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,cpu,scan_fn}(TensorConstant{3}, IncSubtensor{InplaceSet;:int64:}.0, <TensorType(float64, matrix)>, dot.0, dot.0)\nInputs types: [TensorType(int8, scalar), TensorType(float64, 3D), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(float64, matrix)]\nInputs shapes: [(), (4, 1, 20), (20, 20), (2, 20), (2, 20)]\nInputs strides: [(), (160, 160, 8), (160, 8), (160, 8), (160, 8)]\nInputs values: [array(3, dtype=int8), 'not shown', 'not shown', 'not shown', 'not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "def train_model(train_data, epochs=1):\n",
    "    train_errors = []\n",
    "    for i in xrange(epochs):\n",
    "        error = 0\n",
    "#         print(train_data[0])\n",
    "        for textQuestionPair in train_data:\n",
    "            train_X = textQuestionPair[\"text\"]\n",
    "            print(train_X.shape)\n",
    "            train_q = textQuestionPair[\"question\"]\n",
    "            print(train_q.shape)\n",
    "            train_y = textQuestionPair[\"answer\"]\n",
    "            print(train_y.shape)\n",
    "#             print train_y.dtype\n",
    "#             train_X = np.array(textQuestionPair[\"text\"])\n",
    "#             train_q = np.array(textQuestionPair[\"question\"])\n",
    "#             train_y = np.array(textQuestionPair[\"answer\"])\n",
    "            cur_loss = train_MemNN_func(train_X, train_q, train_y)\n",
    "            error += cur_loss\n",
    "        train_errors.append(error)\n",
    "    return train_errors\n",
    "\n",
    "train_errors = train_model(qaPairs)\n",
    "print(train_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
